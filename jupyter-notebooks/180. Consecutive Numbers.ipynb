{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Table: Logs\n",
    "\n",
    "+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| id          | int     |\n",
    "| num         | varchar |\n",
    "+-------------+---------+\n",
    "id is the primary key for this table.\n",
    " \n",
    "\n",
    "Write an SQL query to find all numbers that appear at least three times consecutively.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The query result format is in the following example:\n",
    "\n",
    " \n",
    "\n",
    "Logs table:\n",
    "+----+-----+\n",
    "| Id | Num |\n",
    "+----+-----+\n",
    "| 1  | 1   |\n",
    "| 2  | 1   |\n",
    "| 3  | 1   |\n",
    "| 4  | 2   |\n",
    "| 5  | 1   |\n",
    "| 6  | 2   |\n",
    "| 7  | 2   |\n",
    "+----+-----+\n",
    "\n",
    "Result table:\n",
    "+-----------------+\n",
    "| ConsecutiveNums |\n",
    "+-----------------+\n",
    "| 1               |\n",
    "+-----------------+\n",
    "1 is the only number that appears consecutively for at least three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b320454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f09b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|num|\n",
      "+---+---+\n",
      "|  1|  1|\n",
      "|  2|  1|\n",
      "|  3|  1|\n",
      "|  4|  2|\n",
      "|  5|  1|\n",
      "|  6|  2|\n",
      "|  7|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"consecutive_numbers\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "schema = [\"id\", \"num\"]\n",
    "data = [(1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 2), (7, 2)]\n",
    "\n",
    "logs_df = spark.createDataFrame(data, schema)\n",
    "\n",
    "logs_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5c7b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+\n",
      "| id|num| lag|lead|\n",
      "+---+---+----+----+\n",
      "|  1|  1|null|   1|\n",
      "|  2|  1|   1|   1|\n",
      "|  3|  1|   1|   2|\n",
      "|  4|  2|   1|   1|\n",
      "|  5|  1|   2|   2|\n",
      "|  6|  2|   1|   2|\n",
      "|  7|  2|   2|null|\n",
      "+---+---+----+----+\n",
      "\n",
      "+---------------+\n",
      "|ConsecutiveNums|\n",
      "+---------------+\n",
      "|              1|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lag, lead, col\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "windowSpec = Window.partitionBy().orderBy(\"id\")\n",
    "\n",
    "lag_lead_df = logs_df.withColumn(\"lag\", lag(\"num\").over(windowSpec)).withColumn(\"lead\", lead(\"num\").over(windowSpec))\n",
    "\n",
    "lag_lead_df.show()\n",
    "\n",
    "lag_lead_df.where(\"num = lag = lead\").selectExpr(\"num as ConsecutiveNums\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
