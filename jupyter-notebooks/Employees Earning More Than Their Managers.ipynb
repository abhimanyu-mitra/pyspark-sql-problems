{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8591e5c0",
   "metadata": {},
   "source": [
    "### Employees Earning More Than Their Managers - Leetcode"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ef31245",
   "metadata": {},
   "source": [
    "The Employee table holds all employees including their managers. Every employee has an Id, and there is also a column for the manager Id.\n",
    "\n",
    "+----+-------+--------+-----------+\n",
    "| Id | Name  | Salary | ManagerId |\n",
    "+----+-------+--------+-----------+\n",
    "| 1  | Joe   | 70000  | 3         |\n",
    "| 2  | Henry | 80000  | 4         |\n",
    "| 3  | Sam   | 60000  | NULL      |\n",
    "| 4  | Max   | 90000  | NULL      |\n",
    "+----+-------+--------+-----------+\n",
    "Given the Employee table, write a SQL query that finds out employees who earn more than their managers. For the above table, Joe is the only employee who earns more than his manager.\n",
    "\n",
    "+----------+\n",
    "| Employee |\n",
    "+----------+\n",
    "| Joe      |\n",
    "+----------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1269b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f7319d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+---------+\n",
      "| id| name|salary|managerid|\n",
      "+---+-----+------+---------+\n",
      "|  1|  Joe| 70000|        3|\n",
      "|  2|Henry| 80000|        4|\n",
      "|  3|  Sam| 60000|     null|\n",
      "|  4|  Max| 90000|     null|\n",
      "+---+-----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"emp_earning_more_than_managers\").master(\"local[*]\").getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",4)\n",
    "\n",
    "columns = [\"id\", \"name\", \"salary\", \"managerid\"]\n",
    "data = [(1, \"Joe\", 70000, 3), (2, \"Henry\", 80000, 4), (3, \"Sam\", 60000, None), (4, \"Max\", 90000, None)]\n",
    "\n",
    "emp_df = spark.createDataFrame(data, columns)\n",
    "\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e5cd79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+---------+---+----+------+---------+\n",
      "| id| name|salary|managerid| id|name|salary|managerid|\n",
      "+---+-----+------+---------+---+----+------+---------+\n",
      "|  2|Henry| 80000|        4|  4| Max| 90000|     null|\n",
      "|  1|  Joe| 70000|        3|  3| Sam| 60000|     null|\n",
      "+---+-----+------+---------+---+----+------+---------+\n",
      "\n",
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "| Joe|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We have to self join this table as both the employee and the manager information are present in the same dataframe.\n",
    "# This is hierarchical data.\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "joined_df = emp_df.alias(\"e1\").join(emp_df.alias(\"e2\"), col(\"e1.managerid\") == col(\"e2.id\"), \"inner\")\n",
    "\n",
    "joined_df.show()\n",
    "\n",
    "joined_df.where(\"e1.salary > e2.salary\").select(\"e1.name\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
